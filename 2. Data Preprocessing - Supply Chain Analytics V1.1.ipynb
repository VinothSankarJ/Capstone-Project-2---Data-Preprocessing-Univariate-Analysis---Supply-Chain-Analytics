{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfa47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b349ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Loading\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89429e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Cleaning\n",
    "def data_cleaning(df):\n",
    "    # Handling missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a499b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Transformation\n",
    "def data_transformation(df):\n",
    "    # Example transformation: convert date columns to datetime type\n",
    "    if 'Order Date' in df.columns:\n",
    "        df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6483bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data Integration\n",
    "def data_integration(df, other_dfs):\n",
    "    for other_df in other_dfs:\n",
    "        df = df.merge(other_df, how='left', on='common_column')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67468d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Data Scaling and Encoding\n",
    "def data_scaling_and_encoding(df):\n",
    "    # Identifying numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Creating transformers for numerical and categorical data\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    # Combining transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)])\n",
    "    \n",
    "    return preprocessor, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77fa25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    # Example feature engineering: creating a new feature from existing ones\n",
    "    if 'Order Date' in df.columns:\n",
    "        df['Order Year'] = df['Order Date'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390b3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Validation\n",
    "def data_validation(df):\n",
    "    print(\"Data Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nData Description:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483a2d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Ware_house_ID                 25000 non-null  object \n",
      " 1   WH_Manager_ID                 25000 non-null  object \n",
      " 2   Location_type                 25000 non-null  object \n",
      " 3   WH_capacity_size              25000 non-null  object \n",
      " 4   zone                          25000 non-null  object \n",
      " 5   WH_regional_zone              25000 non-null  object \n",
      " 6   num_refill_req_l3m            25000 non-null  int64  \n",
      " 7   transport_issue_l1y           25000 non-null  int64  \n",
      " 8   Competitor_in_mkt             25000 non-null  int64  \n",
      " 9   retail_shop_num               25000 non-null  int64  \n",
      " 10  wh_owner_type                 25000 non-null  object \n",
      " 11  distributor_num               25000 non-null  int64  \n",
      " 12  flood_impacted                25000 non-null  int64  \n",
      " 13  flood_proof                   25000 non-null  int64  \n",
      " 14  electric_supply               25000 non-null  int64  \n",
      " 15  dist_from_hub                 25000 non-null  int64  \n",
      " 16  workers_num                   25000 non-null  float64\n",
      " 17  wh_est_year                   24996 non-null  float64\n",
      " 18  storage_issue_reported_l3m    25000 non-null  int64  \n",
      " 19  temp_reg_mach                 25000 non-null  int64  \n",
      " 20  approved_wh_govt_certificate  25000 non-null  object \n",
      " 21  wh_breakdown_l3m              25000 non-null  int64  \n",
      " 22  govt_check_l3m                25000 non-null  int64  \n",
      " 23  product_wg_ton                25000 non-null  int64  \n",
      "dtypes: float64(2), int64(14), object(8)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "\n",
      "Data Description:\n",
      "       num_refill_req_l3m  transport_issue_l1y  Competitor_in_mkt  \\\n",
      "count        25000.000000         25000.000000       25000.000000   \n",
      "mean             4.089040             0.773680           3.104200   \n",
      "std              2.606612             1.199449           1.141663   \n",
      "min              0.000000             0.000000           0.000000   \n",
      "25%              2.000000             0.000000           2.000000   \n",
      "50%              4.000000             0.000000           3.000000   \n",
      "75%              6.000000             1.000000           4.000000   \n",
      "max              8.000000             5.000000          12.000000   \n",
      "\n",
      "       retail_shop_num  distributor_num  flood_impacted   flood_proof  \\\n",
      "count     25000.000000     25000.000000    25000.000000  25000.000000   \n",
      "mean       4985.711560        42.418120        0.098160      0.054640   \n",
      "std        1052.825252        16.064329        0.297537      0.227281   \n",
      "min        1821.000000        15.000000        0.000000      0.000000   \n",
      "25%        4313.000000        29.000000        0.000000      0.000000   \n",
      "50%        4859.000000        42.000000        0.000000      0.000000   \n",
      "75%        5500.000000        56.000000        0.000000      0.000000   \n",
      "max       11008.000000        70.000000        1.000000      1.000000   \n",
      "\n",
      "       electric_supply  dist_from_hub   workers_num   wh_est_year  \\\n",
      "count     25000.000000   25000.000000  25000.000000  24996.000000   \n",
      "mean          0.656880     163.537320     28.944640   2009.418107   \n",
      "std           0.474761      62.718609      7.871486      7.529156   \n",
      "min           0.000000      55.000000     10.000000   1996.000000   \n",
      "25%           0.000000     109.000000     24.000000   2003.000000   \n",
      "50%           1.000000     164.000000     28.000000   2009.000000   \n",
      "75%           1.000000     218.000000     33.000000   2016.000000   \n",
      "max           1.000000     271.000000     98.000000   2023.000000   \n",
      "\n",
      "       storage_issue_reported_l3m  temp_reg_mach  wh_breakdown_l3m  \\\n",
      "count                25000.000000   25000.000000      25000.000000   \n",
      "mean                    17.130440       0.303280          3.482040   \n",
      "std                      9.161108       0.459684          1.690335   \n",
      "min                      0.000000       0.000000          0.000000   \n",
      "25%                     10.000000       0.000000          2.000000   \n",
      "50%                     18.000000       0.000000          3.000000   \n",
      "75%                     24.000000       1.000000          5.000000   \n",
      "max                     39.000000       1.000000          6.000000   \n",
      "\n",
      "       govt_check_l3m  product_wg_ton  \n",
      "count    25000.000000    25000.000000  \n",
      "mean        18.812280    22102.632920  \n",
      "std          8.632382    11607.755077  \n",
      "min          1.000000     2065.000000  \n",
      "25%         11.000000    13059.000000  \n",
      "50%         21.000000    22101.000000  \n",
      "75%         26.000000    30103.000000  \n",
      "max         32.000000    55151.000000  \n",
      "\n",
      "Missing Values:\n",
      "Ware_house_ID                   0\n",
      "WH_Manager_ID                   0\n",
      "Location_type                   0\n",
      "WH_capacity_size                0\n",
      "zone                            0\n",
      "WH_regional_zone                0\n",
      "num_refill_req_l3m              0\n",
      "transport_issue_l1y             0\n",
      "Competitor_in_mkt               0\n",
      "retail_shop_num                 0\n",
      "wh_owner_type                   0\n",
      "distributor_num                 0\n",
      "flood_impacted                  0\n",
      "flood_proof                     0\n",
      "electric_supply                 0\n",
      "dist_from_hub                   0\n",
      "workers_num                     0\n",
      "wh_est_year                     4\n",
      "storage_issue_reported_l3m      0\n",
      "temp_reg_mach                   0\n",
      "approved_wh_govt_certificate    0\n",
      "wh_breakdown_l3m                0\n",
      "govt_check_l3m                  0\n",
      "product_wg_ton                  0\n",
      "dtype: int64\n",
      "Shape of df_transformed: (25000, 50038)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (25000, 1), indices imply (25000, 50038)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15252\\491074460.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m    \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15252\\491074460.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m    \u001b[1;31m# Convert the preprocessed data back to DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m    \u001b[0mdf_preprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m    \u001b[1;31m# Save the preprocessed data to a CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aiml\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    715\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m                         \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m                     )\n\u001b[0;32m    719\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aiml\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aiml\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (25000, 1), indices imply (25000, 50038)"
     ]
    }
   ],
   "source": [
    " def main():\n",
    "    # Load the main dataset\n",
    "    df = load_data('Data-1.csv')\n",
    "    \n",
    "    # Perform Data Cleaning\n",
    "    df = data_cleaning(df)\n",
    "    \n",
    "    # Perform Data Transformation\n",
    "    df = data_transformation(df)\n",
    "    \n",
    "    # Perform Feature Engineering\n",
    "    df = feature_engineering(df)\n",
    "    \n",
    "    # Perform Data Validation\n",
    "    data_validation(df)\n",
    "    \n",
    "    # Perform Data Scaling and Encoding\n",
    "    preprocessor, numerical_cols, categorical_cols = data_scaling_and_encoding(df)\n",
    "    \n",
    "    # Fit and transform the entire data\n",
    "    df_transformed = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # Check the shape of df_transformed\n",
    "    print(f\"Shape of df_transformed: {df_transformed.shape}\")\n",
    "    \n",
    "    # Convert the preprocessed data back to DataFrame\n",
    "    df_preprocessed = pd.DataFrame(df_transformed, columns=range(df_transformed.shape[1]))\n",
    "    \n",
    "    # Save the preprocessed data to a CSV file\n",
    "    df_preprocessed.to_csv('Preprocessed_Data.csv', index=False)\n",
    "\n",
    "    print(\"Data preprocessing completed and saved to CSV file.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
